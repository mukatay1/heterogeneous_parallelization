<h1>Assignment 4</h1>
В рамках данной работы были реализованы и исследованы программы, демонстрирующие гибридные и распределённые параллельные вычисления с использованием CUDA и MPI.
Эксперименты были направлены на сравнение времени выполнения последовательных, параллельных и гибридных реализаций при обработке массивов данных.

<h2>Задание 1</h2>

В первом задании была реализована CUDA программа для вычисления суммы элементов массива с использованием глобальной памяти GPU. Каждый поток обрабатывал часть массива, после чего частичные результаты суммировались. Полученный результат и время выполнения были сравнены с последовательной реализацией на CPU для массива размером 100 000 элементов.

<h2>Задание 2</h2>

Во втором задании была реализована CUDA программа для вычисления префиксной суммы (сканирования) массива с использованием разделяемой памяти. Данные загружались в
shared-память блока, после чего выполнялись параллельные вычисления. Время выполнения CUDA реализации было сравнено с последовательной реализацией на CPU
для массива размером 1 000 000 элементов.

<h2>Задание 3</h2>

В третьем задании была реализована гибридная программа, в которой обработка массива выполнялась параллельно на CPU и GPU. Первая часть массива обрабатывалась на CPU,
вторая часть — на GPU. Было выполнено сравнение времени выполнения CPU, GPU и гибридной реализаций.

<h2>Задание 4</h2>

В четвёртом задании была реализована распределённая программа с использованием MPI для обработки массива данных. Исходный массив был разделён между процессами,
выполнены локальные вычисления и сбор результатов. Замеры времени выполнения были проведены для 2, 4 и 8 процессов.

<h2>Ответы на контрольные вопросы</h2>

1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU? 
Гибридные вычисления используют CPU и GPU одновременно, распределяя вычислительную нагрузку между ними.

2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?  
Для задач с большим объёмом параллельных вычислений и высокой вычислительной нагрузкой.

3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?  
Синхронная передача блокирует выполнение программы, асинхронная позволяет выполнять вычисления параллельно с передачей данных.

4. Почему асинхронная передача данных может повысить производительность программы?  
Потому что позволяет перекрывать вычисления и передачу данных, сокращая общее время выполнения.

5. Какие основные функции MPI используются для распределения и сбора данных между процессами?  
MPI_Scatter, MPI_Scatterv, MPI_Gather, MPI_Gatherv и MPI_Reduce.

6. Как количество процессов MPI влияет на время выполнения программы и почему?  
При увеличении числа процессов уменьшается время вычислений, но увеличиваются накладные расходы на обмен данными.

7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?  
Задержки передачи данных, пропускная способность сети и синхронизация процессов.

8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?  
Они оправданы для больших вычислительных задач и неэффективны для малых из-за высоких накладных расходов.
