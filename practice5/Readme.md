Практическая работа №5
Реализация параллельных структур данных на GPU
Цель работы

Освоить программирование параллельных структур данных с использованием CUDA, реализовать параллельный стек и очередь на GPU и исследовать их производительность при одновременном доступе нескольких потоков. 

Теоретические сведения

Параллельные структуры данных обеспечивают безопасный доступ нескольких потоков к общим данным. Для их корректной работы требуется синхронизация и минимизация конфликтов при доступе к памяти.

Основные структуры данных:

Стек (LIFO) — добавление и удаление элементов происходит с одного конца.

Очередь (FIFO) — добавление выполняется в конец, а удаление — из начала.

В CUDA для реализации таких структур используются блоки и потоки, различные типы памяти (глобальная, разделяемая, локальная) и атомарные операции синхронизации.

Практическая часть
Часть 1. Параллельный стек на CUDA

Реализована структура данных «стек» фиксированной ёмкости с использованием атомарных операций atomicAdd и atomicSub для безопасного выполнения операций push и pop.

Было реализовано CUDA-ядро, в котором несколько потоков параллельно выполняют операции добавления и удаления элементов. Корректность работы стека проверена отсутствием выхода за границы и корректным обновлением индекса вершины.

Часть 2. Параллельная очередь на CUDA

Реализована очередь фиксированной ёмкости с использованием атомарных операций для безопасных операций enqueue и dequeue.

Написано CUDA-ядро, в котором потоки параллельно добавляют и извлекают элементы. Проведено сравнение производительности очереди и стека при параллельном доступе.

Результаты и выводы

В ходе работы было показано, что атомарные операции обеспечивают корректность параллельного доступа к структурам данных, однако при высокой конкуренции потоков могут становиться узким местом производительности.

Очередь и стек демонстрируют разные паттерны доступа, что влияет на их масштабируемость. Эффективность реализации во многом зависит от количества атомарных операций и организации доступа к памяти GPU.

Контрольные вопросы

1. В чём отличие стека и очереди?
Стек работает по принципу LIFO, а очередь — по принципу FIFO.

2. Какие проблемы возникают при параллельном доступе к данным?
Возникают гонки данных, конфликты записи и некорректные обновления общих переменных.

3. Как атомарные операции помогают избежать конфликтов?
Атомарные операции гарантируют неделимое обновление общих переменных без вмешательства других потоков.

4. Какие типы памяти CUDA используются?
Глобальная, разделяемая и локальная память.

5. Как синхронизация потоков влияет на производительность?
Синхронизация повышает корректность, но увеличивает накладные расходы и может снижать масштабируемость.

6. Почему разделяемая память важна для оптимизации?
Она обеспечивает более быстрый доступ по сравнению с глобальной памятью и снижает задержки при взаимодействии потоков внутри блока.

Заключение

Практическая работа позволила изучить реализацию и особенности параллельных структур данных на GPU. Полученные результаты показывают важность правильной синхронизации и управления памятью для достижения высокой производительности CUDA-приложений.
