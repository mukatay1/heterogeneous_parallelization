Практическая работа №5
Тема: Реализация параллельных структур данных на GPU
Цель работы

Освоить программирование параллельных структур данных с использованием CUDA. 

Practical Work 5

Реализовать параллельные структуры данных (стек и очередь) на GPU. 

Practical Work 5

Исследовать производительность реализованных структур данных. 

Practical Work 5

Краткая теория

Параллельные структуры данных обеспечивают безопасный доступ нескольких потоков к общим данным, что требует синхронизации и минимизации конфликтов доступа к памяти. 

Practical Work 5

Стек (LIFO): добавление/удаление с одного конца. 

Practical Work 5

Очередь (FIFO): добавление в конец, удаление из начала. 

Practical Work 5

В CUDA важны: организация потоков/блоков, разные типы памяти и механизмы синхронизации. 

Practical Work 5

Практическая часть
Часть 1. Параллельный стек (CUDA)

Задача: реализовать стек фиксированной ёмкости, используя атомарные операции для безопасного push/pop. 

Practical Work 5

Что сделано:

Инициализирован стек с фиксированной ёмкостью (буфер в памяти GPU + поле top). 

Practical Work 5

Написано CUDA-ядро, где несколько потоков параллельно выполняют push и pop. 

Practical Work 5

Выполнена проверка корректности: контролируется, что операции не выходят за границы ёмкости и что извлечённые значения соответствуют ожидаемым условиям работы стека. 

Practical Work 5

Часть 2. Параллельная очередь (CUDA)

Задача: реализовать очередь фиксированной ёмкости с атомарными операциями для безопасных enqueue/dequeue. 

Practical Work 5

Что сделано:

Инициализирована очередь с заданной ёмкостью (буфер + индексы head/tail). 

Practical Work 5

Написано CUDA-ядро, где потоки параллельно выполняют enqueue и dequeue. 

Practical Work 5

Сравнена производительность очереди и стека по времени выполнения и по количеству конфликтов (атомарных операций) при параллельном доступе. 

Practical Work 5

Результаты и выводы

Атомарные операции позволяют обеспечить корректность параллельных push/pop и enqueue/dequeue, но при высокой конкуренции потоков могут становиться узким местом из-за сериализации доступа. 

Practical Work 5

Очередь и стек имеют разные паттерны доступа: очередь часто сильнее страдает от конкуренции за head/tail, особенно при смешанных “производитель/потребитель” сценариях. 

Practical Work 5

Производительность сильно зависит от синхронизации и типа используемой памяти (глобальная/разделяемая/локальная) и от того, насколько часто потоки конфликтуют при атомарных обновлениях. 

Practical Work 5

Контрольные вопросы

1. В чём отличие стека и очереди?
Стек работает по принципу LIFO (последний вошёл — первый вышел), а очередь — FIFO (первый вошёл — первый вышел). 

Practical Work 5

2. Какие проблемы возникают при параллельном доступе к данным?
Основные проблемы — гонки данных, некорректные обновления общих переменных и конфликты при одновременной записи/чтении. 

Practical Work 5

3. Как атомарные операции помогают избежать конфликтов?
Атомарные операции гарантируют, что обновление общей переменной (например, top, head, tail) выполняется как неделимая операция без вмешательства других потоков. 

Practical Work 5

4. Какие типы памяти CUDA используются для хранения данных?
Используются глобальная, разделяемая и локальная память; выбор зависит от скорости доступа и области видимости данных. 

Practical Work 5

5. Как синхронизация потоков влияет на производительность?
Синхронизация повышает корректность, но добавляет накладные расходы и может снижать масштабируемость из-за ожидания и сериализации. 

Practical Work 5

6. Почему разделяемая память важна для оптимизации?
Разделяемая память быстрее глобальной и позволяет уменьшить число обращений к глобальной памяти, ускоряя взаимодействие потоков внутри блока. 

Practical Work 5

Дополнительные задания (по желанию)

Реализовать очередь MPMC (несколько производителей и потребителей). 

Practical Work 5

Оптимизировать использование памяти, включая разделяемую память. 

Practical Work 5

Сравнить производительность с последовательными версиями структур данных. 

Practical Work 5
