<h1>Assignment 3</h1>
В рамках данной работы были реализованы и исследованы несколько CUDA программ, направленных на изучение влияния организации памяти, конфигурации сетки и блоков потоков на производительность GPU приложений. Все эксперименты проводились для массивов размером 1 000 000 элементов, измерение времени выполнялось с использованием CUDA events после предварительного прогрева среды выполнения.

<h2>Задание 1</h2>

В первом задании была реализована CUDA программа для поэлементного умножения массива на заданное число. Были реализованы две версии ядра: первая использует только глобальную память, вторая  разделяемую память. В версии с глобальной памятью каждый поток напрямую читает и записывает данные в глобальную память. В версии с разделяемой памятью данные сначала загружаются в shared-память блока, затем обрабатываются и записываются обратно. Для массива из 1 000 000 элементов было измерено и сравнено время выполнения обеих реализаций.

<h2>Задание 2</h2>

Во втором задании была реализована CUDA программа для поэлементного сложения двух массивов. Исследовалось влияние размера блока потоков на производительность. Одна и та же реализация ядра запускалась с разными значениями blockSize (например, 128, 256 и 512), для каждого варианта измерялось время выполнения. Эксперимент показал, что размер блока влияет на эффективность использования ресурсов GPU и итоговое время выполнения.

<h2>Задание 3</h2>

В третьем задании была реализована CUDA программа, демонстрирующая коалесцированный и некоалесцированный доступ к глобальной памяти. В первой версии соседние потоки обращались к соседним элементам массива, во второй к элементам с большим шагом. Для массива размером 1 000 000 элементов было выполнено сравнение времени выполнения, показавшее преимущество коалесцированного доступа к памяти.

<h2>Задание 4</h2>

В четвёртом задании для CUDA программы из предыдущих заданий был выполнен подбор оптимальной конфигурации сетки и блоков потоков. Программа запускалась с различными значениями blockSize, после чего выбиралась конфигурация с минимальным временем выполнения. Полученные результаты были сравнены с неоптимальной конфигурацией, что позволило показать влияние правильного выбора параметров запуска на производительность.

<h2>Ответы на контрольные вопросы</h2>


1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа? 
В CUDA используются регистры, разделяемая, глобальная, константная и текстурная память.
Регистры и разделяемая память являются самыми быстрыми, а глобальная  самой медленной по времени доступа.
2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы? 
Разделяемая память ускоряет выполнение, когда несколько потоков одного блока многократно используют одни и те же данные.
Это позволяет сократить количество медленных обращений к глобальной памяти
3. Как шаблон доступа к глобальной памяти влияет на производительность GPU программы? 
Последовательный доступ потоков варпа к глобальной памяти значительно повышает производительность.
Несогласованный доступ приводит к увеличению задержек и снижению пропускной способности.
4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти? 
Потому что различные способы доступа к памяти создают разное количество задержек и конфликтов.
Даже при одинаковых вычислениях неэффективная работа с памятью может существенно замедлить выполнение.
5. Как размер блока потоков влияет на производительность CUDA-ядра? 
Размер блока влияет на степень загрузки GPU и количество одновременно выполняемых варпов.
Слишком маленькие или слишком большие блоки могут привести к неэффективному использованию ресурсов.
6. Что такое варп и почему важно учитывать его при разработке CUDA-программ? 
Варп  это группа из 32 потоков, выполняющихся синхронно на GPU.
Разветвления внутри варпа вызывают последовательное выполнение ветвей и снижают производительность.
7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков? 
Необходимо учитывать размер данных, количество регистров, использование разделяемой памяти и аппаратные ограничения GPU.
8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
Потому что большинство CUDA-программ ограничены пропускной способностью памяти, а не вычислениями.
Оптимизация доступа к памяти часто даёт больший прирост производительности, чем изменение самого алгоритма.