Practice 9

Задание 1. Распределённое вычисление среднего значения и стандартного отклонения

В данной задаче реализовано распределённое вычисление среднего значения и стандартного отклонения большого массива случайных чисел с использованием MPI. Массив распределяется между процессами с помощью MPI_Scatterv, а итоговые суммы собираются на процессе с рангом 0 через MPI_Reduce.

Задание 2. Распределённое решение системы линейных уравнений методом Гаусса

Программа реализует параллельное решение системы линейных уравнений методом Гаусса, где строки матрицы распределяются между процессами. Для синхронизации вычислений на этапе прямого хода используется коллективная операция MPI_Bcast.

Задание 3. Параллельный анализ графов (алгоритм Флойда–Уоршелла)

В этом задании реализован параллельный алгоритм Флойда–Уоршелла для поиска кратчайших путей в графе. Обмен обновлёнными частями матрицы расстояний между процессами осуществляется с помощью MPI_Allgather.

Ответы на контрольные вопросы
1. Как изменяется время выполнения программы при увеличении количества процессов? Почему?

При увеличении количества процессов время выполнения обычно уменьшается за счёт параллельной обработки данных, однако после определённого момента выигрыш снижается из-за накладных расходов на обмен сообщениями и синхронизацию.

2. Какие факторы могут влиять на производительность программы?

На производительность влияют объём передаваемых данных, количество процессов, характеристики сети, баланс нагрузки между процессами и эффективность используемых MPI-операций.

3. Как можно оптимизировать передачу данных между процессами?

Оптимизация возможна за счёт уменьшения числа коммуникаций, использования коллективных операций вместо точечных, а также передачи данных большими блоками вместо частых мелких сообщений.

4. Какие ограничения возникают при работе с большими данными?

Основными ограничениями являются объём доступной памяти, пропускная способность сети и рост накладных расходов на коммуникации между процессами.